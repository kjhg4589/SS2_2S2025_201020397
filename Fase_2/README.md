# Proyecto Fase 2 ‚Äì Modelado Predictivo con BigQuery ML

## Universidad de San Carlos de Guatemala  
**Facultad:** Ingenier√≠a  
**Carrera:** Ingenier√≠a en Ciencias y Sistemas  
**Curso:** Seminario de Sistemas 2  

---

- Kevin Josue Hernandez Gomez - 201020397


---

## 2. Objetivo del proyecto
El objetivo de esta fase es dise√±ar, entrenar y evaluar modelos predictivos
utilizando BigQuery ML sobre el dataset NYC Taxi Trips 2022, con el fin de
predecir una variable relevante del negocio y contrastar los valores reales
frente a los valores predichos mediante visualizaciones interactivas.

---

## 3. Dataset utilizado
Se utilizaron las tablas derivadas y optimizadas creadas en la **Fase 1**,
particularmente la tabla:

- `fase_1.trips_q1_opt`

La tabla se encuentra particionada por fecha y clusterizada por ubicaci√≥n,
permitiendo un procesamiento eficiente y controlado de costos.

---

## 4. Definici√≥n del problema de predicci√≥n

En esta fase se abordaron dos problemas de predicci√≥n complementarios,
utilizando t√©cnicas de aprendizaje autom√°tico implementadas directamente
en BigQuery ML:

- **Predicci√≥n del costo total del viaje (`total_amount`)**  
  Se model√≥ como un problema de **regresi√≥n**, con el objetivo de estimar el
  monto total que pagar√° un pasajero a partir de caracter√≠sticas como la
  distancia del viaje, la cantidad de pasajeros, la hora del d√≠a y las
  ubicaciones de origen y destino.

- **Predicci√≥n del m√©todo de pago (`payment_type`)**  
  Se model√≥ como un problema de **clasificaci√≥n**, cuyo objetivo es determinar
  el m√©todo de pago m√°s probable para un viaje, a partir de variables
  operativas y temporales del mismo.

Ambos problemas fueron seleccionados por su relevancia directa en el contexto
del negocio de transporte urbano, ya que permiten anticipar ingresos y
comprender patrones de comportamiento de los usuarios, aportando valor a la
toma de decisiones operativas y estrat√©gicas.


---

## 5. Preparaci√≥n de los datos

Previo al entrenamiento de los modelos predictivos, se realiz√≥ un proceso de
preparaci√≥n y transformaci√≥n de los datos con el objetivo de garantizar la
calidad de la informaci√≥n y la validez de los resultados obtenidos.

Las principales actividades realizadas fueron:

- **Selecci√≥n de variables independientes (features)**  
  Se eligieron variables relevantes desde el punto de vista operativo y
  temporal, tales como la distancia del viaje, la cantidad de pasajeros,
  la hora del d√≠a, el d√≠a de la semana y las ubicaciones de origen y destino.

- **Creaci√≥n de variables derivadas**  
  A partir del campo de fecha y hora del viaje se generaron variables como
  la hora de recogida y el d√≠a de la semana, las cuales permiten capturar
  patrones temporales en el comportamiento de los viajes.

- **Filtrado de registros inv√°lidos o at√≠picos**  
  Se excluyeron viajes con valores inconsistentes, tales como distancias
  negativas o nulas, duraciones inv√°lidas y cantidades de pasajeros fuera
  de rangos razonables, con el fin de reducir el ruido en los datos.

- **Prevenci√≥n de fugas de informaci√≥n (*data leakage*)**  
  Para evitar el uso de informaci√≥n que no estar√≠a disponible al momento de
  realizar una predicci√≥n real, se excluyeron variables directamente
  relacionadas con la variable objetivo del conjunto de caracter√≠sticas
  utilizadas durante el entrenamiento.

--- 
## 6. Divisi√≥n de datos (Train / Test)

Los datos fueron divididos en conjuntos de entrenamiento y prueba con el fin
de evaluar el desempe√±o de los modelos de manera objetiva y reproducible.

- **Entrenamiento:** 80% de los registros  
- **Prueba:** 20% de los registros  

La estrategia de divisi√≥n utilizada fue **aleatoria controlada**, implementada
mediante una funci√≥n hash (`FARM_FINGERPRINT`) aplicada sobre un conjunto de
campos del viaje. Esta t√©cnica permite asignar cada registro de forma
determin√≠stica a uno de los conjuntos, asegurando que la misma observaci√≥n no
aparezca simult√°neamente en entrenamiento y prueba.

Esta estrategia garantiza una evaluaci√≥n consistente del desempe√±o de los
modelos, manteniendo una distribuci√≥n representativa de los datos en ambos
conjuntos.


---

## 7. Modelos implementados

Para abordar los problemas de predicci√≥n definidos, se entrenaron modelos
utilizando BigQuery ML, seleccionando algoritmos adecuados seg√∫n la naturaleza
de cada variable objetivo.

### 7.1 Predicci√≥n del costo total del viaje (Regresi√≥n)

- **Modelo 1: Regresi√≥n Lineal (`LINEAR_REG`)**  
  - **Objetivo:** Estimar el costo total del viaje (`total_amount`) a partir de
    variables operativas y temporales.  
  - **Justificaci√≥n:** Este modelo fue utilizado como l√≠nea base por su
    simplicidad e interpretabilidad, permitiendo identificar relaciones
    lineales entre las variables independientes y la variable objetivo.

- **Modelo 2: √Årboles Potenciados (`BOOSTED_TREE_REGRESSOR`)**  
  - **Objetivo:** Estimar el costo total del viaje (`total_amount`).  
  - **Justificaci√≥n:** Este modelo permite capturar relaciones no lineales y
    combinaciones complejas entre las variables, lo que suele resultar en un
    mejor desempe√±o predictivo en problemas de regresi√≥n con m√∫ltiples
    factores.

---

### 7.2 Predicci√≥n del m√©todo de pago (Clasificaci√≥n)

- **Modelo 3: Regresi√≥n Log√≠stica (`LOGISTIC_REG`)**  
  - **Objetivo:** Clasificar el m√©todo de pago del viaje, modelado como un
    problema de clasificaci√≥n binaria (tarjeta vs efectivo).  
  - **Justificaci√≥n:** La regresi√≥n log√≠stica es un modelo ampliamente utilizado
    en problemas de clasificaci√≥n binaria, ofreciendo una interpretaci√≥n clara
    de las probabilidades asociadas a cada clase.

- **Modelo 4: √Årboles Potenciados (`BOOSTED_TREE_CLASSIFIER`)**  
  - **Objetivo:** Clasificar el m√©todo de pago del viaje.  
  - **Justificaci√≥n:** Este modelo fue incluido para capturar relaciones no
    lineales entre las variables explicativas y el m√©todo de pago, permitiendo
    comparar su desempe√±o frente a un modelo lineal de referencia.


---

## 8. Evaluaci√≥n de modelos

El desempe√±o de los modelos entrenados fue evaluado utilizando la funci√≥n
`ML.EVALUATE` de BigQuery ML, aplicando el mismo conjunto de datos de prueba
para garantizar una comparaci√≥n justa entre los modelos.

### M√©tricas utilizadas

- **Modelos de regresi√≥n (costo del viaje):**
  - *Mean Absolute Error (MAE)*
  - *Root Mean Squared Error (RMSE)*
  - *R¬≤ Score*

- **Modelos de clasificaci√≥n (m√©todo de pago):**
  - *Accuracy*
  - *Precision*
  - *Recall*
  - *F1-Score*
  - *ROC AUC*

Estas m√©tricas permiten evaluar tanto la precisi√≥n de las predicciones como
la capacidad de generalizaci√≥n de cada modelo.

---

### Comparaci√≥n de desempe√±o

Los resultados obtenidos para cada par de modelos fueron comparados utilizando
las m√©tricas correspondientes a su tipo de problema. Para la regresi√≥n, se
analiz√≥ la reducci√≥n del error entre el modelo lineal y el modelo de √°rboles
potenciados. Para la clasificaci√≥n, se compararon las m√©tricas de exactitud y
discriminaci√≥n entre la regresi√≥n log√≠stica y el clasificador basado en
√°rboles.

Esta comparaci√≥n permiti√≥ identificar el modelo con mejor desempe√±o para cada
problema de predicci√≥n, el cual fue seleccionado para la generaci√≥n de
predicciones y su posterior visualizaci√≥n.

---

## 9. Modelo seleccionado y justificaci√≥n
Con base en las m√©tricas obtenidas y consideraciones de interpretabilidad
y desempe√±o, se seleccion√≥ el modelo:

- **Modelo final:** Modelo 1 

Este modelo present√≥ mejores resultados para el problema planteado.

---

## 10. Generaci√≥n de predicciones
Se generaron predicciones sobre el conjunto de prueba utilizando
`ML.PREDICT`, almacenando los resultados en una tabla/vista para su
posterior an√°lisis y visualizaci√≥n.

---

## 11. Visualizaci√≥n de resultados
Se desarroll√≥ un tablero interactivo en Google Looker Studio
que permite:

- Comparar valores reales vs valores predichos
- Analizar el error del modelo
- Visualizar el comportamiento de las predicciones por variables relevantes

üîó **Enlace al tablero:**  
(Agregar enlace aqu√≠)

---

## 12. Hallazgos relevantes
Entre los principales hallazgos se identificaron:

- (Ejemplo: mejor desempe√±o del modelo en ciertos rangos horarios)
- (Ejemplo: mayor error en viajes de larga distancia)
- (Ejemplo: variables con mayor impacto en la predicci√≥n)

---

## 13. Consideraciones sobre sesgos y limitaciones
Se identifican posibles sesgos en los datos, como variaciones por zona o
horario, los cuales pueden influir en las predicciones del modelo y deben
ser considerados al interpretar los resultados.

---

## 14. Organizaci√≥n del repositorio
La estructura del repositorio para la Fase 2 es la siguiente:

```text
Fase_2/
‚îÇ
‚îú‚îÄ‚îÄ sql/
‚îÇ   ‚îú‚îÄ‚îÄ preparacion_datos.sql
‚îÇ   ‚îú‚îÄ‚îÄ entrenamiento_modelo_1.sql
‚îÇ   ‚îú‚îÄ‚îÄ entrenamiento_modelo_2.sql
‚îÇ   ‚îú‚îÄ‚îÄ evaluacion_modelos.sql
‚îÇ   ‚îî‚îÄ‚îÄ predicciones.sql
‚îÇ
‚îú‚îÄ‚îÄ evidencias/
‚îÇ   ‚îú‚îÄ‚îÄ entrenamiento_modelos.png
‚îÇ   ‚îú‚îÄ‚îÄ metricas_evaluacion.png
‚îÇ   ‚îî‚îÄ‚îÄ predicciones.png
‚îÇ
‚îî‚îÄ‚îÄ README.md
